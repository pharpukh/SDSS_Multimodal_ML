{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c3dec39-b7f0-4fa8-9820-4b8c768dbac8",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11599844-c352-40de-9ad0-76db1dee6824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff58d9fe-71fb-423b-adb9-592dad2f2840",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c220d578-0443-4b88-bce8-b6019fe8ae4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CUBE_PATH = \"../sdss_cube_sfr/SDSS_cube_lean.h5\"\n",
    "\n",
    "with h5py.File(CUBE_PATH, \"r\") as cube:\n",
    "    spectra = cube[\"dense_cube/0/ml_spectrum/spectral_1d_cube_zoom_0\"][:]\n",
    "    images = cube[\"dense_cube/0/ml_image/cutout_3d_cube_zoom_0\"][:]\n",
    "    metadata = cube[\"dense_cube/0/ml_spectrum/spec_metadata_refs\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e87ab394-cb14-4fd8-85f4-61e33ecc0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfrs = pd.read_hdf(CUBE_PATH, key=\"fits_spectra_metadata_star_formation_rates\")\n",
    "\n",
    "valid_sfrs = sfrs[(sfrs[\"FLAG\"] == 0.0) & (sfrs[\"Z\"].notna())].copy()\n",
    "metadata_indices = metadata[:, 0][\"ds_slice_idx\"]\n",
    "mask = np.in1d(metadata_indices, valid_sfrs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5821aedf-3c6a-4f5c-af25-fd4c460bd2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\", \".join(sfrs.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d127bda-06ba-478a-ae17-3138a23df7ed",
   "metadata": {},
   "source": [
    "### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51e675a4-5ad6-48a0-97bb-467d3d7827b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_filtered = spectra[mask]\n",
    "images_filtered = images[mask]\n",
    "metadata_indices_filtered = metadata_indices[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef97c756-24a2-433c-82a2-2c0b522aa25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = valid_sfrs.loc[metadata_indices_filtered, \"TARGETTYPE\"]\n",
    "redshifts = valid_sfrs.loc[metadata_indices_filtered, \"Z\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6e10164-8157-4bf1-a210-f0c6e4446ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_targettype(val):\n",
    "    if isinstance(val, bytes):\n",
    "        val = val.decode(\"utf-8\").strip()\n",
    "    else:\n",
    "        val = str(val).strip()\n",
    "    return \"GALAXY\" if \"GALAXY\" in val else \"OTHER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28391e78-795d-48f3-b52d-635164b9033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_simplified = pd.Series(labels).apply(simplify_targettype).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91489901-f8e0-4f82-a25d-79010a5f7f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_mask = labels_simplified == \"GALAXY\"\n",
    "spectra_filtered = spectra_filtered[galaxy_mask]\n",
    "images_filtered = images_filtered[galaxy_mask]\n",
    "redshifts = redshifts[galaxy_mask]\n",
    "\n",
    "nan_mask = ~np.isnan(spectra_filtered).any(axis=1)\n",
    "spectra_filtered = spectra_filtered[nan_mask]\n",
    "images_filtered = images_filtered[nan_mask]\n",
    "redshifts = redshifts[nan_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbc77357-f97f-46bc-ae83-c00733497e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_spectra(spec):\n",
    "    min_val = np.min(spec, axis=1, keepdims=True)\n",
    "    max_val = np.max(spec, axis=1, keepdims=True)\n",
    "    return 2 * (spec - min_val) / (max_val - min_val) - 1\n",
    "\n",
    "spectra_normalized = normalize_spectra(spectra_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9832fd8-018b-4418-bd0f-265d7b32ddc5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "filters = [\"u\", \"g\", \"r\", \"i\", \"z\"]\n",
    "\n",
    "def plot_images_and_spectrum(images, spectra, labels, redshifts, class_name, obj_num):\n",
    "    class_index = np.where(labels == class_name)[0]\n",
    "    if len(class_index) > 0:\n",
    "        idx = class_index[obj_num]\n",
    "        img_channels = images[idx]\n",
    "        spectrum = spectra[idx]\n",
    "        redshift = redshifts[idx] if not np.isnan(redshifts[idx]) else \"N/A\"\n",
    "        \n",
    "        fig = plt.figure(figsize=(15, 8))\n",
    "        gs = gridspec.GridSpec(2, 1, height_ratios=[1, 0.5])\n",
    "        gs_images = gs[0].subgridspec(1, 5, wspace=0.1)\n",
    "        \n",
    "        for i in range(5):\n",
    "            ax = fig.add_subplot(gs_images[0, i])\n",
    "            ax.imshow(img_channels[i], cmap=\"viridis\")\n",
    "            ax.set_title(f\"{class_name} - {filters[i]}\", fontsize=9)\n",
    "            ax.axis(\"off\")\n",
    "        \n",
    "        ax_spec = fig.add_subplot(gs[1])\n",
    "        wavelengths = np.linspace(3800, 9200, len(spectrum))\n",
    "        ax_spec.plot(wavelengths, spectrum, color=\"blue\")\n",
    "        ax_spec.set_title(f\"{class_name} - Spectrum (z={redshift:.3f})\", fontsize=9)\n",
    "        ax_spec.set_xlabel(\"Wavelength (Ã…)\", fontsize=9)\n",
    "        ax_spec.set_ylabel(\"Flux\", fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No images found for class: {class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d48dcc-3122-47d7-aec5-15a31460acaa",
   "metadata": {},
   "source": [
    "# Machine Learning for SFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f846f205-aba7-4fa3-9afc-25a291bd6ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = valid_sfrs.loc[metadata_indices_filtered, [\"AVG\", \"ENTROPY\", \"MEDIAN\", \"MODE\", \"P16\", \"P2P5\", \"P84\", \"P97P5\"]].values\n",
    "y = y[galaxy_mask]\n",
    "y = y[nan_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7abf79d9-5dbd-45e7-bb7e-39dd08c89d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(y.shape[0])\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce5b4c8f-a770-4944-9dd9-772ab61fa016",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "X_spec_train, X_spec_test = spectra_normalized[train_idx], spectra_normalized[test_idx]\n",
    "X_photo = images_filtered.reshape(images_filtered.shape[0], -1)\n",
    "X_photo_train, X_photo_test = X_photo[train_idx], X_photo[test_idx]\n",
    "X_comb_train = np.concatenate([X_spec_train, X_photo_train], axis=1)\n",
    "X_comb_test = np.concatenate([X_spec_test, X_photo_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81949270-5057-4a92-9067-670c8740daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_spec_train_scaled = scaler.fit_transform(X_spec_train)\n",
    "X_spec_test_scaled = scaler.transform(X_spec_test)\n",
    "X_photo_train_scaled = scaler.fit_transform(X_photo_train)\n",
    "X_photo_test_scaled = scaler.transform(X_photo_test)\n",
    "X_comb_train_scaled = scaler.fit_transform(X_comb_train)\n",
    "X_comb_test_scaled = scaler.transform(X_comb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c023da6-c0be-4afc-b745-fb6afbf6705f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rustafar/miniconda3/envs/myenv/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/rustafar/miniconda3/envs/myenv/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.5399  |  0:00:05s\n",
      "epoch 1  | loss: 1.08571 |  0:00:06s\n",
      "epoch 2  | loss: 0.82952 |  0:00:08s\n",
      "epoch 3  | loss: 0.6221  |  0:00:09s\n",
      "epoch 4  | loss: 0.591   |  0:00:11s\n",
      "epoch 5  | loss: 0.58049 |  0:00:13s\n",
      "epoch 6  | loss: 0.57796 |  0:00:14s\n",
      "epoch 7  | loss: 0.57637 |  0:00:16s\n",
      "epoch 8  | loss: 0.57949 |  0:00:17s\n",
      "epoch 9  | loss: 0.57569 |  0:00:19s\n",
      "epoch 10 | loss: 0.58217 |  0:00:20s\n",
      "epoch 11 | loss: 0.57658 |  0:00:22s\n",
      "epoch 12 | loss: 0.57717 |  0:00:23s\n",
      "epoch 13 | loss: 0.57057 |  0:00:25s\n",
      "epoch 14 | loss: 0.56798 |  0:00:26s\n",
      "epoch 15 | loss: 0.57084 |  0:00:28s\n",
      "epoch 16 | loss: 0.57182 |  0:00:30s\n",
      "epoch 17 | loss: 0.56829 |  0:00:31s\n",
      "epoch 18 | loss: 0.56961 |  0:00:33s\n",
      "epoch 19 | loss: 0.56944 |  0:00:34s\n",
      "epoch 20 | loss: 0.57231 |  0:00:36s\n",
      "epoch 21 | loss: 0.56995 |  0:00:37s\n",
      "epoch 22 | loss: 0.57526 |  0:00:39s\n",
      "epoch 23 | loss: 0.57216 |  0:00:40s\n",
      "epoch 24 | loss: 0.56962 |  0:00:42s\n",
      "epoch 25 | loss: 0.57112 |  0:00:43s\n",
      "epoch 26 | loss: 0.56943 |  0:00:45s\n",
      "epoch 27 | loss: 0.56798 |  0:00:46s\n",
      "epoch 28 | loss: 0.57217 |  0:00:48s\n",
      "epoch 29 | loss: 0.56972 |  0:00:49s\n",
      "epoch 30 | loss: 0.56978 |  0:00:51s\n",
      "epoch 31 | loss: 0.57089 |  0:00:53s\n",
      "epoch 32 | loss: 0.57029 |  0:00:54s\n",
      "epoch 33 | loss: 0.57254 |  0:00:56s\n",
      "epoch 34 | loss: 0.56792 |  0:00:57s\n",
      "epoch 35 | loss: 0.5679  |  0:00:59s\n",
      "epoch 36 | loss: 0.56685 |  0:01:00s\n",
      "epoch 37 | loss: 0.57295 |  0:01:02s\n",
      "epoch 38 | loss: 0.57178 |  0:01:03s\n",
      "epoch 39 | loss: 0.57258 |  0:01:05s\n",
      "epoch 40 | loss: 0.56908 |  0:01:07s\n",
      "epoch 41 | loss: 0.57246 |  0:01:08s\n",
      "epoch 42 | loss: 0.5702  |  0:01:10s\n",
      "epoch 43 | loss: 0.56999 |  0:01:11s\n",
      "epoch 44 | loss: 0.57342 |  0:01:13s\n",
      "epoch 45 | loss: 0.57131 |  0:01:14s\n",
      "epoch 46 | loss: 0.56922 |  0:01:16s\n",
      "epoch 47 | loss: 0.57288 |  0:01:17s\n",
      "epoch 48 | loss: 0.57023 |  0:01:19s\n",
      "epoch 49 | loss: 0.57024 |  0:01:20s\n",
      "epoch 50 | loss: 0.56818 |  0:01:22s\n",
      "epoch 51 | loss: 0.56846 |  0:01:23s\n",
      "epoch 52 | loss: 0.56826 |  0:01:25s\n",
      "epoch 53 | loss: 0.56813 |  0:01:27s\n",
      "epoch 54 | loss: 0.56828 |  0:01:28s\n",
      "epoch 55 | loss: 0.56593 |  0:01:30s\n",
      "epoch 56 | loss: 0.56516 |  0:01:31s\n",
      "epoch 57 | loss: 0.56345 |  0:01:33s\n",
      "epoch 58 | loss: 0.56448 |  0:01:34s\n",
      "epoch 59 | loss: 0.56294 |  0:01:36s\n",
      "epoch 60 | loss: 0.56326 |  0:01:37s\n",
      "epoch 61 | loss: 0.5626  |  0:01:39s\n",
      "epoch 62 | loss: 0.56464 |  0:01:41s\n",
      "epoch 63 | loss: 0.56308 |  0:01:42s\n",
      "epoch 64 | loss: 0.56168 |  0:01:44s\n",
      "epoch 65 | loss: 0.56354 |  0:01:45s\n",
      "epoch 66 | loss: 0.56279 |  0:01:47s\n",
      "epoch 67 | loss: 0.56246 |  0:01:48s\n",
      "epoch 68 | loss: 0.56275 |  0:01:50s\n",
      "epoch 69 | loss: 0.56547 |  0:01:51s\n",
      "epoch 70 | loss: 0.56326 |  0:01:53s\n",
      "epoch 71 | loss: 0.56477 |  0:01:55s\n",
      "epoch 72 | loss: 0.56395 |  0:01:56s\n",
      "epoch 73 | loss: 0.56905 |  0:01:58s\n",
      "epoch 74 | loss: 0.56804 |  0:01:59s\n",
      "epoch 75 | loss: 0.56762 |  0:02:01s\n",
      "epoch 76 | loss: 0.57145 |  0:02:02s\n",
      "epoch 77 | loss: 0.57022 |  0:02:04s\n",
      "epoch 78 | loss: 0.56767 |  0:02:05s\n",
      "epoch 79 | loss: 0.56605 |  0:02:07s\n",
      "epoch 80 | loss: 0.56516 |  0:02:08s\n",
      "epoch 81 | loss: 0.56747 |  0:02:10s\n",
      "epoch 82 | loss: 0.56943 |  0:02:11s\n",
      "epoch 83 | loss: 0.56843 |  0:02:13s\n",
      "epoch 84 | loss: 0.56696 |  0:02:15s\n",
      "epoch 85 | loss: 0.56887 |  0:02:16s\n",
      "epoch 86 | loss: 0.56661 |  0:02:18s\n",
      "epoch 87 | loss: 0.5659  |  0:02:19s\n",
      "epoch 88 | loss: 0.56602 |  0:02:21s\n",
      "epoch 89 | loss: 0.56697 |  0:02:22s\n",
      "epoch 90 | loss: 0.56393 |  0:02:24s\n",
      "epoch 91 | loss: 0.56472 |  0:02:25s\n",
      "epoch 92 | loss: 0.56462 |  0:02:27s\n",
      "epoch 93 | loss: 0.56372 |  0:02:29s\n",
      "epoch 94 | loss: 0.5638  |  0:02:30s\n",
      "epoch 95 | loss: 0.56502 |  0:02:32s\n",
      "epoch 96 | loss: 0.56262 |  0:02:33s\n",
      "epoch 97 | loss: 0.5661  |  0:02:35s\n",
      "epoch 98 | loss: 0.56445 |  0:02:36s\n",
      "epoch 99 | loss: 0.56359 |  0:02:38s\n",
      "epoch 100| loss: 0.56457 |  0:02:39s\n",
      "epoch 101| loss: 0.56711 |  0:02:41s\n",
      "epoch 102| loss: 0.56193 |  0:02:42s\n",
      "epoch 103| loss: 0.56223 |  0:02:44s\n",
      "epoch 104| loss: 0.56513 |  0:02:45s\n",
      "epoch 105| loss: 0.5681  |  0:02:47s\n",
      "epoch 106| loss: 0.56822 |  0:02:48s\n",
      "epoch 107| loss: 0.56298 |  0:02:50s\n",
      "epoch 108| loss: 0.56628 |  0:02:52s\n",
      "epoch 109| loss: 0.56377 |  0:02:53s\n",
      "epoch 110| loss: 0.56445 |  0:02:55s\n",
      "epoch 111| loss: 0.56379 |  0:02:56s\n",
      "epoch 112| loss: 0.56493 |  0:02:58s\n",
      "epoch 113| loss: 0.56693 |  0:02:59s\n",
      "epoch 114| loss: 0.56648 |  0:03:01s\n",
      "epoch 115| loss: 0.56942 |  0:03:02s\n",
      "epoch 116| loss: 0.56833 |  0:03:04s\n",
      "epoch 117| loss: 0.57023 |  0:03:05s\n",
      "epoch 118| loss: 0.56645 |  0:03:07s\n",
      "epoch 119| loss: 0.56593 |  0:03:08s\n",
      "epoch 120| loss: 0.56484 |  0:03:10s\n",
      "epoch 121| loss: 0.56791 |  0:03:12s\n",
      "epoch 122| loss: 0.56739 |  0:03:13s\n",
      "epoch 123| loss: 0.56567 |  0:03:15s\n",
      "epoch 124| loss: 0.56507 |  0:03:16s\n",
      "epoch 125| loss: 0.56538 |  0:03:18s\n",
      "epoch 126| loss: 0.56381 |  0:03:19s\n",
      "epoch 127| loss: 0.56661 |  0:03:21s\n",
      "epoch 128| loss: 0.56691 |  0:03:22s\n",
      "epoch 129| loss: 0.56627 |  0:03:24s\n",
      "epoch 130| loss: 0.5649  |  0:03:26s\n",
      "epoch 131| loss: 0.56623 |  0:03:27s\n",
      "epoch 132| loss: 0.56639 |  0:03:29s\n",
      "epoch 133| loss: 0.5647  |  0:03:30s\n",
      "epoch 134| loss: 0.56592 |  0:03:32s\n",
      "epoch 135| loss: 0.56585 |  0:03:33s\n",
      "epoch 136| loss: 0.56572 |  0:03:35s\n",
      "epoch 137| loss: 0.56515 |  0:03:36s\n",
      "epoch 138| loss: 0.56634 |  0:03:38s\n",
      "epoch 139| loss: 0.56562 |  0:03:40s\n",
      "epoch 140| loss: 0.56595 |  0:03:41s\n",
      "epoch 141| loss: 0.56528 |  0:03:43s\n",
      "epoch 142| loss: 0.56302 |  0:03:44s\n",
      "epoch 143| loss: 0.56481 |  0:03:46s\n",
      "epoch 144| loss: 0.56337 |  0:03:47s\n",
      "epoch 145| loss: 0.56618 |  0:03:49s\n",
      "epoch 146| loss: 0.56322 |  0:03:50s\n",
      "epoch 147| loss: 0.56354 |  0:03:52s\n",
      "epoch 148| loss: 0.564   |  0:03:53s\n",
      "epoch 149| loss: 0.56421 |  0:03:55s\n",
      "epoch 150| loss: 0.56394 |  0:03:57s\n",
      "epoch 151| loss: 0.56528 |  0:03:58s\n",
      "epoch 152| loss: 0.56609 |  0:04:00s\n",
      "epoch 153| loss: 0.56591 |  0:04:01s\n",
      "epoch 154| loss: 0.56507 |  0:04:03s\n",
      "epoch 155| loss: 0.56326 |  0:04:04s\n",
      "epoch 156| loss: 0.56234 |  0:04:06s\n",
      "epoch 157| loss: 0.56257 |  0:04:07s\n",
      "epoch 158| loss: 0.56518 |  0:04:09s\n",
      "epoch 159| loss: 0.56735 |  0:04:10s\n",
      "epoch 160| loss: 0.56408 |  0:04:12s\n",
      "epoch 161| loss: 0.56547 |  0:04:13s\n",
      "epoch 162| loss: 0.56575 |  0:04:15s\n",
      "epoch 163| loss: 0.5663  |  0:04:17s\n",
      "epoch 164| loss: 0.56627 |  0:04:18s\n",
      "epoch 165| loss: 0.56536 |  0:04:20s\n",
      "epoch 166| loss: 0.56583 |  0:04:21s\n",
      "epoch 167| loss: 0.56758 |  0:04:23s\n",
      "epoch 168| loss: 0.56464 |  0:04:24s\n",
      "epoch 169| loss: 0.56371 |  0:04:26s\n",
      "epoch 170| loss: 0.56608 |  0:04:27s\n",
      "epoch 171| loss: 0.56895 |  0:04:29s\n",
      "epoch 172| loss: 0.56524 |  0:04:30s\n",
      "epoch 173| loss: 0.56655 |  0:04:32s\n",
      "epoch 174| loss: 0.56533 |  0:04:33s\n",
      "epoch 175| loss: 0.56602 |  0:04:35s\n",
      "epoch 176| loss: 0.56577 |  0:04:37s\n",
      "epoch 177| loss: 0.56426 |  0:04:38s\n",
      "epoch 178| loss: 0.56326 |  0:04:40s\n",
      "epoch 179| loss: 0.56137 |  0:04:41s\n",
      "epoch 180| loss: 0.56581 |  0:04:43s\n",
      "epoch 181| loss: 0.56725 |  0:04:44s\n",
      "epoch 182| loss: 0.5671  |  0:04:46s\n",
      "epoch 183| loss: 0.56796 |  0:04:48s\n",
      "epoch 184| loss: 0.5655  |  0:04:49s\n",
      "epoch 185| loss: 0.56571 |  0:04:51s\n",
      "epoch 186| loss: 0.56433 |  0:04:52s\n",
      "epoch 187| loss: 0.5633  |  0:04:54s\n",
      "epoch 188| loss: 0.56454 |  0:04:55s\n",
      "epoch 189| loss: 0.56304 |  0:04:57s\n",
      "epoch 190| loss: 0.56378 |  0:04:58s\n",
      "epoch 191| loss: 0.56588 |  0:05:00s\n",
      "epoch 192| loss: 0.56755 |  0:05:02s\n",
      "epoch 193| loss: 0.56796 |  0:05:03s\n",
      "epoch 194| loss: 0.56512 |  0:05:05s\n",
      "epoch 195| loss: 0.5623  |  0:05:06s\n",
      "epoch 196| loss: 0.56426 |  0:05:08s\n",
      "epoch 197| loss: 0.56532 |  0:05:09s\n",
      "epoch 198| loss: 0.56401 |  0:05:11s\n",
      "epoch 199| loss: 0.56347 |  0:05:12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rustafar/miniconda3/envs/myenv/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/rustafar/miniconda3/envs/myenv/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 10.51246|  0:00:08s\n",
      "epoch 1  | loss: 4.46478 |  0:00:17s\n",
      "epoch 2  | loss: 2.67589 |  0:00:25s\n",
      "epoch 3  | loss: 1.21878 |  0:00:34s\n",
      "epoch 4  | loss: 1.02759 |  0:00:42s\n",
      "epoch 5  | loss: 0.69071 |  0:00:51s\n",
      "epoch 6  | loss: 0.64338 |  0:00:59s\n",
      "epoch 7  | loss: 0.60085 |  0:01:08s\n",
      "epoch 8  | loss: 0.58933 |  0:01:16s\n",
      "epoch 9  | loss: 0.58554 |  0:01:25s\n",
      "epoch 10 | loss: 0.58508 |  0:01:33s\n",
      "epoch 11 | loss: 0.58192 |  0:01:42s\n",
      "epoch 12 | loss: 0.5841  |  0:01:50s\n",
      "epoch 13 | loss: 0.58322 |  0:01:59s\n",
      "epoch 14 | loss: 0.57872 |  0:02:07s\n",
      "epoch 15 | loss: 0.58732 |  0:02:16s\n",
      "epoch 16 | loss: 0.57988 |  0:02:25s\n",
      "epoch 17 | loss: 0.58118 |  0:02:33s\n",
      "epoch 18 | loss: 0.58505 |  0:02:42s\n",
      "epoch 19 | loss: 0.58196 |  0:02:50s\n",
      "epoch 20 | loss: 0.58288 |  0:02:59s\n",
      "epoch 21 | loss: 0.57974 |  0:03:07s\n",
      "epoch 22 | loss: 0.58444 |  0:03:16s\n",
      "epoch 23 | loss: 0.57854 |  0:03:24s\n",
      "epoch 24 | loss: 0.57728 |  0:03:33s\n",
      "epoch 25 | loss: 0.57837 |  0:03:41s\n",
      "epoch 26 | loss: 0.57797 |  0:03:50s\n",
      "epoch 27 | loss: 0.57706 |  0:03:58s\n",
      "epoch 28 | loss: 0.57794 |  0:04:07s\n",
      "epoch 29 | loss: 0.57578 |  0:04:15s\n",
      "epoch 30 | loss: 0.57393 |  0:04:24s\n",
      "epoch 31 | loss: 0.57798 |  0:04:32s\n",
      "epoch 32 | loss: 0.57823 |  0:04:41s\n",
      "epoch 33 | loss: 0.57805 |  0:04:49s\n",
      "epoch 34 | loss: 0.57895 |  0:04:58s\n",
      "epoch 35 | loss: 0.57562 |  0:05:06s\n",
      "epoch 36 | loss: 0.57915 |  0:05:15s\n",
      "epoch 37 | loss: 0.58036 |  0:05:23s\n",
      "epoch 38 | loss: 0.58006 |  0:05:32s\n",
      "epoch 39 | loss: 0.5799  |  0:05:40s\n",
      "epoch 40 | loss: 0.58091 |  0:05:49s\n",
      "epoch 41 | loss: 0.5762  |  0:05:57s\n",
      "epoch 42 | loss: 0.57466 |  0:06:06s\n",
      "epoch 43 | loss: 0.57746 |  0:06:14s\n",
      "epoch 44 | loss: 0.57686 |  0:06:23s\n",
      "epoch 45 | loss: 0.57241 |  0:06:31s\n",
      "epoch 46 | loss: 0.5736  |  0:06:40s\n",
      "epoch 47 | loss: 0.56925 |  0:06:48s\n",
      "epoch 48 | loss: 0.56997 |  0:06:57s\n",
      "epoch 49 | loss: 0.56902 |  0:07:05s\n",
      "epoch 50 | loss: 0.56405 |  0:07:14s\n",
      "epoch 51 | loss: 0.56285 |  0:07:22s\n",
      "epoch 52 | loss: 0.55933 |  0:07:31s\n",
      "epoch 53 | loss: 0.55896 |  0:07:39s\n",
      "epoch 54 | loss: 0.53942 |  0:07:48s\n",
      "epoch 55 | loss: 0.53145 |  0:07:56s\n",
      "epoch 56 | loss: 0.50789 |  0:08:05s\n",
      "epoch 57 | loss: 0.50343 |  0:08:13s\n",
      "epoch 58 | loss: 0.48836 |  0:08:22s\n",
      "epoch 59 | loss: 0.47893 |  0:08:30s\n",
      "epoch 60 | loss: 0.47592 |  0:08:39s\n",
      "epoch 61 | loss: 0.45568 |  0:08:47s\n",
      "epoch 62 | loss: 0.47435 |  0:08:56s\n",
      "epoch 63 | loss: 0.50108 |  0:09:04s\n",
      "epoch 64 | loss: 0.49053 |  0:09:13s\n",
      "epoch 65 | loss: 0.46798 |  0:09:21s\n",
      "epoch 66 | loss: 0.45716 |  0:09:30s\n",
      "epoch 67 | loss: 0.46828 |  0:09:38s\n",
      "epoch 68 | loss: 0.45301 |  0:09:47s\n",
      "epoch 69 | loss: 0.44996 |  0:09:55s\n",
      "epoch 70 | loss: 0.49329 |  0:10:04s\n",
      "epoch 71 | loss: 0.4411  |  0:10:12s\n",
      "epoch 72 | loss: 0.42162 |  0:10:21s\n",
      "epoch 73 | loss: 0.41546 |  0:10:30s\n",
      "epoch 74 | loss: 0.39953 |  0:10:38s\n",
      "epoch 75 | loss: 0.4     |  0:10:47s\n",
      "epoch 76 | loss: 0.38164 |  0:10:55s\n",
      "epoch 77 | loss: 0.38162 |  0:11:04s\n",
      "epoch 78 | loss: 0.3958  |  0:11:12s\n",
      "epoch 79 | loss: 0.39128 |  0:11:21s\n",
      "epoch 80 | loss: 0.38819 |  0:11:29s\n",
      "epoch 81 | loss: 0.3762  |  0:11:38s\n",
      "epoch 82 | loss: 0.36112 |  0:11:46s\n",
      "epoch 83 | loss: 0.37104 |  0:11:55s\n",
      "epoch 84 | loss: 0.35172 |  0:12:03s\n",
      "epoch 85 | loss: 0.34234 |  0:12:12s\n",
      "epoch 86 | loss: 0.33548 |  0:12:20s\n",
      "epoch 87 | loss: 0.33111 |  0:12:29s\n",
      "epoch 88 | loss: 0.31709 |  0:12:37s\n",
      "epoch 89 | loss: 0.31436 |  0:12:46s\n",
      "epoch 90 | loss: 0.30772 |  0:12:54s\n",
      "epoch 91 | loss: 0.31656 |  0:13:03s\n",
      "epoch 92 | loss: 0.337   |  0:13:11s\n",
      "epoch 93 | loss: 0.31992 |  0:13:20s\n",
      "epoch 94 | loss: 0.29545 |  0:13:28s\n",
      "epoch 95 | loss: 0.28737 |  0:13:37s\n",
      "epoch 96 | loss: 0.27387 |  0:13:45s\n",
      "epoch 97 | loss: 0.27673 |  0:13:54s\n",
      "epoch 98 | loss: 0.28691 |  0:14:02s\n",
      "epoch 99 | loss: 0.27455 |  0:14:11s\n",
      "epoch 100| loss: 0.26393 |  0:14:19s\n",
      "epoch 101| loss: 0.26578 |  0:14:28s\n",
      "epoch 102| loss: 0.25137 |  0:14:36s\n",
      "epoch 103| loss: 0.25743 |  0:14:45s\n",
      "epoch 104| loss: 0.25227 |  0:14:53s\n",
      "epoch 105| loss: 0.26547 |  0:15:02s\n",
      "epoch 106| loss: 0.26012 |  0:15:10s\n",
      "epoch 107| loss: 0.25227 |  0:15:19s\n",
      "epoch 108| loss: 0.25443 |  0:15:27s\n",
      "epoch 109| loss: 0.24973 |  0:15:36s\n",
      "epoch 110| loss: 0.26461 |  0:15:44s\n",
      "epoch 111| loss: 0.24875 |  0:15:53s\n",
      "epoch 112| loss: 0.23626 |  0:16:01s\n",
      "epoch 113| loss: 0.22254 |  0:16:10s\n",
      "epoch 114| loss: 0.21651 |  0:16:18s\n",
      "epoch 115| loss: 0.21797 |  0:16:27s\n",
      "epoch 116| loss: 0.21199 |  0:16:35s\n",
      "epoch 117| loss: 0.20866 |  0:16:44s\n",
      "epoch 118| loss: 0.20457 |  0:16:52s\n",
      "epoch 119| loss: 0.19715 |  0:17:01s\n",
      "epoch 120| loss: 0.1926  |  0:17:09s\n",
      "epoch 121| loss: 0.19073 |  0:17:18s\n",
      "epoch 122| loss: 0.18543 |  0:17:26s\n",
      "epoch 123| loss: 0.18565 |  0:17:35s\n",
      "epoch 124| loss: 0.18373 |  0:17:43s\n",
      "epoch 125| loss: 0.20209 |  0:17:52s\n",
      "epoch 126| loss: 0.19363 |  0:18:01s\n",
      "epoch 127| loss: 0.17787 |  0:18:09s\n",
      "epoch 128| loss: 0.17054 |  0:18:18s\n",
      "epoch 129| loss: 0.1664  |  0:18:26s\n",
      "epoch 130| loss: 0.16276 |  0:18:35s\n",
      "epoch 131| loss: 0.16054 |  0:18:43s\n",
      "epoch 132| loss: 0.167   |  0:18:52s\n",
      "epoch 133| loss: 0.15372 |  0:19:00s\n",
      "epoch 134| loss: 0.15404 |  0:19:09s\n",
      "epoch 135| loss: 0.15328 |  0:19:17s\n",
      "epoch 136| loss: 0.14637 |  0:19:26s\n",
      "epoch 137| loss: 0.21169 |  0:19:34s\n",
      "epoch 138| loss: 0.2076  |  0:19:43s\n",
      "epoch 139| loss: 0.18161 |  0:19:51s\n",
      "epoch 140| loss: 0.16485 |  0:20:00s\n",
      "epoch 141| loss: 0.16478 |  0:20:08s\n",
      "epoch 142| loss: 0.16051 |  0:20:17s\n",
      "epoch 143| loss: 0.18201 |  0:20:25s\n",
      "epoch 144| loss: 0.165   |  0:20:34s\n",
      "epoch 145| loss: 0.15035 |  0:20:42s\n",
      "epoch 146| loss: 0.14173 |  0:20:51s\n",
      "epoch 147| loss: 0.13704 |  0:20:59s\n",
      "epoch 148| loss: 0.13091 |  0:21:08s\n",
      "epoch 149| loss: 0.16261 |  0:21:16s\n",
      "epoch 150| loss: 0.15526 |  0:21:25s\n",
      "epoch 151| loss: 0.13522 |  0:21:33s\n",
      "epoch 152| loss: 0.12979 |  0:21:42s\n",
      "epoch 153| loss: 0.13158 |  0:21:50s\n",
      "epoch 154| loss: 0.13041 |  0:21:59s\n",
      "epoch 155| loss: 0.12478 |  0:22:07s\n",
      "epoch 156| loss: 0.12759 |  0:22:16s\n",
      "epoch 157| loss: 0.12708 |  0:22:24s\n",
      "epoch 158| loss: 0.12543 |  0:22:33s\n",
      "epoch 159| loss: 0.11796 |  0:22:41s\n",
      "epoch 160| loss: 0.11758 |  0:22:50s\n",
      "epoch 161| loss: 0.11343 |  0:22:58s\n",
      "epoch 162| loss: 0.11508 |  0:23:07s\n",
      "epoch 163| loss: 0.11786 |  0:23:16s\n",
      "epoch 164| loss: 0.13141 |  0:23:24s\n",
      "epoch 165| loss: 0.12291 |  0:23:33s\n",
      "epoch 166| loss: 0.1153  |  0:23:41s\n",
      "epoch 167| loss: 0.11142 |  0:23:50s\n",
      "epoch 168| loss: 0.11353 |  0:23:58s\n",
      "epoch 169| loss: 0.10535 |  0:24:07s\n",
      "epoch 170| loss: 0.09874 |  0:24:15s\n",
      "epoch 171| loss: 0.10773 |  0:24:24s\n",
      "epoch 172| loss: 0.10602 |  0:24:32s\n",
      "epoch 173| loss: 0.10319 |  0:24:41s\n",
      "epoch 174| loss: 0.10357 |  0:24:49s\n",
      "epoch 175| loss: 0.1018  |  0:24:58s\n",
      "epoch 176| loss: 0.09763 |  0:25:06s\n",
      "epoch 177| loss: 0.09486 |  0:25:15s\n",
      "epoch 178| loss: 0.12441 |  0:25:23s\n",
      "epoch 179| loss: 0.11342 |  0:25:32s\n",
      "epoch 180| loss: 0.11086 |  0:25:40s\n",
      "epoch 181| loss: 0.1063  |  0:25:49s\n",
      "epoch 182| loss: 0.11726 |  0:25:57s\n",
      "epoch 183| loss: 0.10019 |  0:26:06s\n",
      "epoch 184| loss: 0.09362 |  0:26:14s\n",
      "epoch 185| loss: 0.09813 |  0:26:23s\n",
      "epoch 186| loss: 0.09736 |  0:26:31s\n",
      "epoch 187| loss: 0.10233 |  0:26:40s\n",
      "epoch 188| loss: 0.09539 |  0:26:48s\n",
      "epoch 189| loss: 0.08878 |  0:26:57s\n",
      "epoch 190| loss: 0.08401 |  0:27:05s\n",
      "epoch 191| loss: 0.08616 |  0:27:14s\n",
      "epoch 192| loss: 0.08435 |  0:27:22s\n",
      "epoch 193| loss: 0.0807  |  0:27:31s\n",
      "epoch 194| loss: 0.08062 |  0:27:39s\n",
      "epoch 195| loss: 0.08342 |  0:27:48s\n",
      "epoch 196| loss: 0.07785 |  0:27:56s\n",
      "epoch 197| loss: 0.07907 |  0:28:05s\n",
      "epoch 198| loss: 0.0747  |  0:28:13s\n",
      "epoch 199| loss: 0.07864 |  0:28:22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rustafar/miniconda3/envs/myenv/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/rustafar/miniconda3/envs/myenv/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 7.99162 |  0:00:12s\n",
      "epoch 1  | loss: 2.61452 |  0:00:24s\n",
      "epoch 2  | loss: 1.41326 |  0:00:36s\n",
      "epoch 3  | loss: 0.91298 |  0:00:48s\n",
      "epoch 4  | loss: 0.7389  |  0:01:00s\n",
      "epoch 5  | loss: 0.6656  |  0:01:12s\n",
      "epoch 6  | loss: 0.65535 |  0:01:24s\n",
      "epoch 7  | loss: 0.62572 |  0:01:37s\n",
      "epoch 8  | loss: 0.5991  |  0:01:49s\n",
      "epoch 9  | loss: 0.58203 |  0:02:01s\n",
      "epoch 10 | loss: 0.58761 |  0:02:13s\n",
      "epoch 11 | loss: 0.58224 |  0:02:25s\n",
      "epoch 12 | loss: 0.5729  |  0:02:37s\n",
      "epoch 13 | loss: 0.57386 |  0:02:50s\n",
      "epoch 14 | loss: 0.58062 |  0:03:02s\n",
      "epoch 15 | loss: 0.57927 |  0:03:14s\n",
      "epoch 16 | loss: 0.57831 |  0:03:26s\n",
      "epoch 17 | loss: 0.58124 |  0:03:39s\n",
      "epoch 18 | loss: 0.57593 |  0:03:51s\n",
      "epoch 19 | loss: 0.57421 |  0:04:03s\n",
      "epoch 20 | loss: 0.57038 |  0:04:15s\n",
      "epoch 21 | loss: 0.56691 |  0:04:27s\n",
      "epoch 22 | loss: 0.56625 |  0:04:40s\n",
      "epoch 23 | loss: 0.56664 |  0:04:52s\n",
      "epoch 24 | loss: 0.56686 |  0:05:04s\n",
      "epoch 25 | loss: 0.56985 |  0:05:16s\n",
      "epoch 26 | loss: 0.56356 |  0:05:28s\n",
      "epoch 27 | loss: 0.56307 |  0:05:41s\n",
      "epoch 28 | loss: 0.56748 |  0:05:53s\n",
      "epoch 29 | loss: 0.5711  |  0:06:05s\n",
      "epoch 30 | loss: 0.56487 |  0:06:17s\n",
      "epoch 31 | loss: 0.57049 |  0:06:29s\n",
      "epoch 32 | loss: 0.56579 |  0:06:41s\n",
      "epoch 33 | loss: 0.563   |  0:06:54s\n",
      "epoch 34 | loss: 0.56929 |  0:07:06s\n",
      "epoch 35 | loss: 0.56796 |  0:07:18s\n",
      "epoch 36 | loss: 0.56701 |  0:07:30s\n",
      "epoch 37 | loss: 0.56776 |  0:07:42s\n",
      "epoch 38 | loss: 0.57315 |  0:07:55s\n",
      "epoch 39 | loss: 0.57012 |  0:08:07s\n",
      "epoch 40 | loss: 0.57127 |  0:08:19s\n",
      "epoch 41 | loss: 0.56627 |  0:08:31s\n",
      "epoch 42 | loss: 0.5641  |  0:08:43s\n",
      "epoch 43 | loss: 0.56672 |  0:08:56s\n",
      "epoch 44 | loss: 0.56192 |  0:09:08s\n",
      "epoch 45 | loss: 0.55995 |  0:09:20s\n",
      "epoch 46 | loss: 0.55663 |  0:09:32s\n",
      "epoch 47 | loss: 0.56109 |  0:09:44s\n",
      "epoch 48 | loss: 0.57034 |  0:09:56s\n",
      "epoch 49 | loss: 0.57158 |  0:10:09s\n",
      "epoch 50 | loss: 0.57059 |  0:10:21s\n",
      "epoch 51 | loss: 0.57253 |  0:10:33s\n",
      "epoch 52 | loss: 0.56865 |  0:10:45s\n",
      "epoch 53 | loss: 0.56985 |  0:10:57s\n",
      "epoch 54 | loss: 0.57385 |  0:11:10s\n",
      "epoch 55 | loss: 0.57178 |  0:11:22s\n",
      "epoch 56 | loss: 0.56546 |  0:11:34s\n",
      "epoch 57 | loss: 0.5688  |  0:11:46s\n",
      "epoch 58 | loss: 0.56784 |  0:11:58s\n",
      "epoch 59 | loss: 0.56624 |  0:12:11s\n",
      "epoch 60 | loss: 0.56555 |  0:12:23s\n",
      "epoch 61 | loss: 0.5645  |  0:12:35s\n",
      "epoch 62 | loss: 0.56982 |  0:12:47s\n",
      "epoch 63 | loss: 0.56551 |  0:12:59s\n",
      "epoch 64 | loss: 0.56678 |  0:13:11s\n",
      "epoch 65 | loss: 0.56194 |  0:13:24s\n",
      "epoch 66 | loss: 0.56634 |  0:13:36s\n",
      "epoch 67 | loss: 0.56916 |  0:13:48s\n",
      "epoch 68 | loss: 0.56527 |  0:14:00s\n",
      "epoch 69 | loss: 0.56413 |  0:14:12s\n",
      "epoch 70 | loss: 0.56507 |  0:14:25s\n",
      "epoch 71 | loss: 0.56622 |  0:14:37s\n",
      "epoch 72 | loss: 0.56351 |  0:14:49s\n",
      "epoch 73 | loss: 0.56294 |  0:15:01s\n",
      "epoch 74 | loss: 0.56303 |  0:15:13s\n",
      "epoch 75 | loss: 0.5657  |  0:15:26s\n",
      "epoch 76 | loss: 0.56487 |  0:15:38s\n",
      "epoch 77 | loss: 0.56483 |  0:15:50s\n",
      "epoch 78 | loss: 0.5594  |  0:16:02s\n",
      "epoch 79 | loss: 0.55863 |  0:16:14s\n",
      "epoch 80 | loss: 0.55996 |  0:16:26s\n",
      "epoch 81 | loss: 0.55836 |  0:16:39s\n",
      "epoch 82 | loss: 0.56069 |  0:16:51s\n",
      "epoch 83 | loss: 0.56258 |  0:17:03s\n",
      "epoch 84 | loss: 0.56119 |  0:17:15s\n",
      "epoch 85 | loss: 0.55838 |  0:17:27s\n",
      "epoch 86 | loss: 0.56029 |  0:17:40s\n",
      "epoch 87 | loss: 0.56238 |  0:17:52s\n",
      "epoch 88 | loss: 0.56686 |  0:18:04s\n",
      "epoch 89 | loss: 0.55977 |  0:18:16s\n",
      "epoch 90 | loss: 0.55894 |  0:18:28s\n",
      "epoch 91 | loss: 0.55932 |  0:18:41s\n",
      "epoch 92 | loss: 0.56121 |  0:18:53s\n",
      "epoch 93 | loss: 0.56116 |  0:19:05s\n",
      "epoch 94 | loss: 0.55874 |  0:19:17s\n",
      "epoch 95 | loss: 0.55654 |  0:19:29s\n",
      "epoch 96 | loss: 0.56228 |  0:19:41s\n",
      "epoch 97 | loss: 0.56052 |  0:19:54s\n",
      "epoch 98 | loss: 0.56383 |  0:20:06s\n",
      "epoch 99 | loss: 0.55687 |  0:20:18s\n",
      "epoch 100| loss: 0.55971 |  0:20:30s\n",
      "epoch 101| loss: 0.55931 |  0:20:42s\n",
      "epoch 102| loss: 0.56252 |  0:20:55s\n",
      "epoch 103| loss: 0.56086 |  0:21:07s\n",
      "epoch 104| loss: 0.55894 |  0:21:19s\n",
      "epoch 105| loss: 0.56108 |  0:21:31s\n",
      "epoch 106| loss: 0.55683 |  0:21:43s\n",
      "epoch 107| loss: 0.55823 |  0:21:56s\n",
      "epoch 108| loss: 0.55796 |  0:22:08s\n",
      "epoch 109| loss: 0.55995 |  0:22:20s\n",
      "epoch 110| loss: 0.55859 |  0:22:32s\n",
      "epoch 111| loss: 0.55858 |  0:22:44s\n",
      "epoch 112| loss: 0.56111 |  0:22:56s\n",
      "epoch 113| loss: 0.55686 |  0:23:09s\n",
      "epoch 114| loss: 0.5575  |  0:23:21s\n",
      "epoch 115| loss: 0.56061 |  0:23:33s\n",
      "epoch 116| loss: 0.55778 |  0:23:45s\n",
      "epoch 117| loss: 0.55755 |  0:23:57s\n",
      "epoch 118| loss: 0.55862 |  0:24:10s\n",
      "epoch 119| loss: 0.56233 |  0:24:22s\n",
      "epoch 120| loss: 0.56242 |  0:24:34s\n",
      "epoch 121| loss: 0.56115 |  0:24:46s\n",
      "epoch 122| loss: 0.56633 |  0:24:58s\n",
      "epoch 123| loss: 0.56241 |  0:25:11s\n",
      "epoch 124| loss: 0.56164 |  0:25:23s\n",
      "epoch 125| loss: 0.56348 |  0:25:35s\n",
      "epoch 126| loss: 0.56057 |  0:25:47s\n",
      "epoch 127| loss: 0.56208 |  0:25:59s\n",
      "epoch 128| loss: 0.56231 |  0:26:11s\n",
      "epoch 129| loss: 0.56128 |  0:26:24s\n",
      "epoch 130| loss: 0.56106 |  0:26:36s\n",
      "epoch 131| loss: 0.56111 |  0:26:48s\n",
      "epoch 132| loss: 0.55951 |  0:27:00s\n",
      "epoch 133| loss: 0.55404 |  0:27:12s\n",
      "epoch 134| loss: 0.55716 |  0:27:25s\n",
      "epoch 135| loss: 0.56081 |  0:27:37s\n",
      "epoch 136| loss: 0.56017 |  0:27:49s\n",
      "epoch 137| loss: 0.55824 |  0:28:01s\n",
      "epoch 138| loss: 0.555   |  0:28:13s\n",
      "epoch 139| loss: 0.55199 |  0:28:25s\n",
      "epoch 140| loss: 0.55111 |  0:28:38s\n",
      "epoch 141| loss: 0.53591 |  0:28:50s\n",
      "epoch 142| loss: 0.52943 |  0:29:02s\n",
      "epoch 143| loss: 0.5315  |  0:29:14s\n",
      "epoch 144| loss: 0.52716 |  0:29:26s\n",
      "epoch 145| loss: 0.52765 |  0:29:39s\n",
      "epoch 146| loss: 0.52115 |  0:29:51s\n",
      "epoch 147| loss: 0.52429 |  0:30:03s\n",
      "epoch 148| loss: 0.52466 |  0:30:15s\n",
      "epoch 149| loss: 0.51857 |  0:30:27s\n",
      "epoch 150| loss: 0.52247 |  0:30:40s\n",
      "epoch 151| loss: 0.5248  |  0:30:52s\n",
      "epoch 152| loss: 0.52798 |  0:31:04s\n",
      "epoch 153| loss: 0.52947 |  0:31:16s\n",
      "epoch 154| loss: 0.5306  |  0:31:28s\n",
      "epoch 155| loss: 0.52945 |  0:31:41s\n",
      "epoch 156| loss: 0.54284 |  0:31:53s\n",
      "epoch 157| loss: 0.52816 |  0:32:05s\n",
      "epoch 158| loss: 0.52148 |  0:32:17s\n",
      "epoch 159| loss: 0.52101 |  0:32:29s\n",
      "epoch 160| loss: 0.51962 |  0:32:41s\n",
      "epoch 161| loss: 0.51938 |  0:32:54s\n",
      "epoch 162| loss: 0.51823 |  0:33:06s\n",
      "epoch 163| loss: 0.51798 |  0:33:18s\n",
      "epoch 164| loss: 0.51888 |  0:33:30s\n",
      "epoch 165| loss: 0.5229  |  0:33:42s\n",
      "epoch 166| loss: 0.5218  |  0:33:55s\n",
      "epoch 167| loss: 0.52545 |  0:34:07s\n",
      "epoch 168| loss: 0.52312 |  0:34:19s\n",
      "epoch 169| loss: 0.52504 |  0:34:31s\n",
      "epoch 170| loss: 0.52362 |  0:34:43s\n",
      "epoch 171| loss: 0.51814 |  0:34:55s\n",
      "epoch 172| loss: 0.51617 |  0:35:08s\n",
      "epoch 173| loss: 0.51232 |  0:35:20s\n",
      "epoch 174| loss: 0.51545 |  0:35:32s\n",
      "epoch 175| loss: 0.52244 |  0:35:44s\n",
      "epoch 176| loss: 0.52149 |  0:35:56s\n",
      "epoch 177| loss: 0.52146 |  0:36:08s\n",
      "epoch 178| loss: 0.52116 |  0:36:21s\n",
      "epoch 179| loss: 0.51751 |  0:36:33s\n",
      "epoch 180| loss: 0.51637 |  0:36:45s\n",
      "epoch 181| loss: 0.51841 |  0:36:57s\n",
      "epoch 182| loss: 0.51888 |  0:37:09s\n",
      "epoch 183| loss: 0.5191  |  0:37:21s\n",
      "epoch 184| loss: 0.51803 |  0:37:34s\n",
      "epoch 185| loss: 0.51999 |  0:37:46s\n",
      "epoch 186| loss: 0.51803 |  0:37:58s\n",
      "epoch 187| loss: 0.51823 |  0:38:10s\n",
      "epoch 188| loss: 0.52222 |  0:38:22s\n",
      "epoch 189| loss: 0.51957 |  0:38:35s\n",
      "epoch 190| loss: 0.51834 |  0:38:47s\n",
      "epoch 191| loss: 0.51619 |  0:38:59s\n",
      "epoch 192| loss: 0.51702 |  0:39:11s\n",
      "epoch 193| loss: 0.5218  |  0:39:23s\n",
      "epoch 194| loss: 0.52072 |  0:39:35s\n",
      "epoch 195| loss: 0.51921 |  0:39:48s\n",
      "epoch 196| loss: 0.51618 |  0:40:00s\n",
      "epoch 197| loss: 0.52433 |  0:40:12s\n",
      "epoch 198| loss: 0.51794 |  0:40:24s\n",
      "epoch 199| loss: 0.52135 |  0:40:36s\n"
     ]
    }
   ],
   "source": [
    "def train_tabnet(X_train, y_train, X_test):\n",
    "    model = TabNetRegressor(\n",
    "        n_d=64, n_a=64, n_steps=7,\n",
    "        gamma=1.5, lambda_sparse=0.0001,\n",
    "        momentum=0.7, mask_type=\"entmax\"\n",
    "    )\n",
    "    model.fit(X_train, y_train, max_epochs=200, patience=30, batch_size=256, virtual_batch_size=128)\n",
    "    return model.predict(X_test)\n",
    "\n",
    "y_pred_spec_tab = train_tabnet(X_spec_train_scaled, y_train, X_spec_test_scaled)\n",
    "y_pred_photo_tab = train_tabnet(X_photo_train_scaled, y_train, X_photo_test_scaled)\n",
    "y_pred_comb_tab = train_tabnet(X_comb_train_scaled, y_train, X_comb_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46eb8e04-ed5b-42c2-b172-f7576111ee16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean model MAE: 0.6163717097520727\n",
      "Spectrum model MAE (TabNet): 0.6071666175166874\n",
      "Photo model MAE (TabNet): 0.5036490425747494\n",
      "Combination model MAE (TabNet): 0.5891615369827254\n"
     ]
    }
   ],
   "source": [
    "y_mean = np.full_like(y_test, np.mean(y_train, axis=0))\n",
    "mae_mean = mean_absolute_error(y_test, y_mean)\n",
    "\n",
    "mae_spec_tab = mean_absolute_error(y_test, y_pred_spec_tab)\n",
    "mae_photo_tab = mean_absolute_error(y_test, y_pred_photo_tab)\n",
    "mae_comb_tab = mean_absolute_error(y_test, y_pred_comb_tab)\n",
    "\n",
    "print(\"Mean model MAE:\", mae_mean)\n",
    "print(\"Spectrum model MAE (TabNet):\", mae_spec_tab)\n",
    "print(\"Photo model MAE (TabNet):\", mae_photo_tab)\n",
    "print(\"Combination model MAE (TabNet):\", mae_comb_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e54327da-9927-43af-b2f0-bf6d3a572c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              y_test  \\\n",
      "0  [-0.4525999128818512, -5.7508357269963755, -0....   \n",
      "1  [-0.2147999107837677, -5.758284017535481, -0.1...   \n",
      "2  [0.37796008586883545, -4.434794977749806, 0.34...   \n",
      "3  [-1.3138599395751953, -5.47998471566957, -1.26...   \n",
      "4  [0.4476400911808014, -4.724946891551867, 0.424...   \n",
      "5  [0.13043010234832764, -4.487824326584547, 0.10...   \n",
      "6  [0.7521800994873047, -3.3737913659710284, 0.70...   \n",
      "7  [-1.4386299848556519, -5.80033062012948, -1.34...   \n",
      "8  [0.07596009224653244, -4.853448751780046, 0.04...   \n",
      "9  [0.2064300924539566, -4.926453766562226, 0.186...   \n",
      "\n",
      "                                     y_pred_spec_tab  \\\n",
      "0  [-0.26803556, -5.15075, -0.2480962, -0.1462267...   \n",
      "1  [-0.2959844, -5.3948207, -0.26265803, -0.14058...   \n",
      "2  [-0.33333322, -5.44071, -0.30643123, -0.200913...   \n",
      "3  [-0.12509161, -5.0243163, -0.11539796, -0.0381...   \n",
      "4  [-0.28625694, -5.30781, -0.26523438, -0.165015...   \n",
      "5  [-0.37707242, -5.36875, -0.34114948, -0.213469...   \n",
      "6  [-0.06345662, -4.8356752, -0.06787248, -0.0140...   \n",
      "7  [-0.4287251, -5.412672, -0.3883986, -0.2557644...   \n",
      "8  [-0.19680667, -5.1479254, -0.18128005, -0.0954...   \n",
      "9  [-0.21160921, -5.090715, -0.20038769, -0.11866...   \n",
      "\n",
      "                                    y_pred_photo_tab  \\\n",
      "0  [-0.4632991, -5.556895, -0.39113638, -0.206579...   \n",
      "1  [-0.43085706, -5.534327, -0.36188126, -0.18280...   \n",
      "2  [0.20811641, -4.6628, 0.1839968, 0.20797753, -...   \n",
      "3  [-0.17143366, -4.5218353, -0.20430967, -0.1965...   \n",
      "4  [0.21423334, -4.825128, 0.19532216, 0.23057538...   \n",
      "5  [-0.34373343, -5.485849, -0.29070276, -0.13622...   \n",
      "6  [0.042987347, -4.4989133, 0.014097393, 0.02920...   \n",
      "7  [-0.20114386, -5.048724, -0.20597327, -0.14686...   \n",
      "8  [0.1587398, -4.8362913, 0.14205194, 0.17987007...   \n",
      "9  [-0.1856882, -4.7704377, -0.20513561, -0.17377...   \n",
      "\n",
      "                                     y_pred_comb_tab  \n",
      "0  [-0.31860766, -5.2912645, -0.2839013, -0.15479...  \n",
      "1  [-0.0660588, -4.86016, -0.063787885, 0.0074775...  \n",
      "2  [-0.22046128, -5.1711097, -0.19925784, -0.0948...  \n",
      "3  [-0.34544167, -4.66609, -0.36714885, -0.362648...  \n",
      "4  [-0.4271479, -5.3674965, -0.37235677, -0.20309...  \n",
      "5  [-0.27590483, -5.0736704, -0.25118297, -0.1428...  \n",
      "6  [-0.82716405, -5.6806154, -0.77720416, -0.6164...  \n",
      "7  [-0.13235535, -4.7442927, -0.12526831, -0.0457...  \n",
      "8  [-0.07329284, -4.8027687, -0.07984144, -0.0261...  \n",
      "9  [-0.31309104, -4.633631, -0.3357313, -0.337751...  \n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    \"y_test\": list(y_test),\n",
    "    \"y_pred_spec_tab\": list(y_pred_spec_tab),\n",
    "    \"y_pred_photo_tab\": list(y_pred_photo_tab),\n",
    "    \"y_pred_comb_tab\": list(y_pred_comb_tab)\n",
    "})\n",
    "print(df_results.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
